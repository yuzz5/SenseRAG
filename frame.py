# frame.py - æ„å»ºè§†é¢‘å¸§å‘é‡æ•°æ®åº“ï¼ˆä»¥ clip_id ä¸ºä¸»é”®ï¼‰

import os
import shutil
from PIL import Image
import torch
from transformers import CLIPProcessor, CLIPModel
import numpy as np
import chromadb
import re

# --- é…ç½® ---
root_frame_dir = "/root/autodl-tmp/Multimodal_AIGC/frames"
output_dir = "/root/autodl-tmp/Multimodal_AIGC/chroma_db"
label_file_path = "/root/autodl-tmp/Multimodal_AIGC/labels.txt"
os.makedirs(output_dir, exist_ok=True)

# è¾“å‡ºå­ç›®å½•
copied_frames_base_dir = os.path.join(output_dir, "copied_frames")
os.makedirs(copied_frames_base_dir, exist_ok=True)
last_frames_dir = os.path.join(output_dir, "last_frames")
os.makedirs(last_frames_dir, exist_ok=True)
collection_name = "video_frames"

# --- åˆå§‹åŒ–æ¨¡å‹ ---
device = "cuda" if torch.cuda.is_available() else "cpu"
model_name = "/root/autodl-tmp/Multimodal_AIGC/models/openai/clip-vit-base-patch32"
print("ğŸš€ æ­£åœ¨åŠ è½½ CLIP æ¨¡å‹...")
model = CLIPModel.from_pretrained(model_name).to(device)
processor = CLIPProcessor.from_pretrained(model_name)
print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

# --- åˆå§‹åŒ– ChromaDB ---
chroma_client = chromadb.PersistentClient(path=output_dir)

# ğŸ‘‡ å®‰å…¨åˆ é™¤æ—§é›†åˆ
try:
    existing_collections = chroma_client.list_collections()
    if collection_name in [c.name for c in existing_collections]:
        chroma_client.delete_collection(name=collection_name)
        print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§é›†åˆ '{collection_name}'")
    else:
        print(f"â„¹ï¸ é›†åˆ '{collection_name}' ä¸å­˜åœ¨ï¼Œå°†æ–°å»º")
except Exception as e:
    print(f"âš ï¸ åˆ é™¤é›†åˆæ—¶å‡ºé”™ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")

# åˆ›å»ºæ–°é›†åˆ
try:
    chroma_collection = chroma_client.create_collection(name=collection_name)
    print(f"âœ… æˆåŠŸåˆ›å»ºæ–°é›†åˆ '{collection_name}'")
except Exception as e:
    print(f"âŒ åˆ›å»ºé›†åˆå¤±è´¥: {e}")
    raise

# --- å­˜å‚¨åˆ—è¡¨ ---
all_embeddings = []
all_frame_ids = []
all_metadatas = []

# --- è¾…åŠ©å‡½æ•°ï¼šä»æ–‡ä»¶åæå–å¸§åºå· ---
def extract_frame_info(filename):
    try:
        name_part, ext = os.path.splitext(filename)
        if name_part.startswith("frame_"):
            number_str = name_part[6:]
            if number_str.isdigit():
                return int(number_str)
        return None
    except:
        return None

# --- è¾…åŠ©å‡½æ•°ï¼šè§£æå­ç›®å½•åï¼ˆæ”¯æŒä¸¤ç§æ ¼å¼ï¼‰---
def extract_subfolder_info(subfolder_name):
    """
    æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
    1. {label}_{video_id}_{start}_{end}
       â†’ Chainsaw_0M3AYnUPk4g_0.00_10.00
    2. {label}_{video_id}_suffix_{start}_{end}
       â†’ Traffic_accident_LQTQt2-QzGU_0208_5.00_10.00

    è¿”å›: (label, clip_id, start, end, original_video_id)
    """
    # æ¨¡å¼1: label_videoId_start_end
    pattern_simple = r'^([a-zA-Z_]+)_([a-zA-Z0-9_-]{11})_(\d+\.?\d*)_([\d\.]+)$'

    # æ¨¡å¼2: label_videoId_suffix_start_end
    pattern_complex = r'^([a-zA-Z_]+)_([a-zA-Z0-9_-]+)_(\d+)_(\d+\.?\d*)_(\d+\.?\d*)$'

    match_simple = re.match(pattern_simple, subfolder_name)
    if match_simple:
        label = match_simple.group(1)
        video_id = match_simple.group(2)  # çº¯è§†é¢‘ID
        start = float(match_simple.group(3))
        end = float(match_simple.group(4))
        clip_id = video_id  # ç‰‡æ®µID = è§†é¢‘IDï¼ˆæ— åç¼€ï¼‰
        return label, clip_id, start, end, video_id

    match_complex = re.match(pattern_complex, subfolder_name)
    if match_complex:
        label = match_complex.group(1)
        original_video_id = match_complex.group(2)
        suffix_num = match_complex.group(3)
        start = float(match_complex.group(4))
        end = float(match_complex.group(5))
        clip_id = f"{original_video_id}_{suffix_num}"  # å®Œæ•´ç‰‡æ®µID
        return label, clip_id, start, end, original_video_id

    print(f"âŒ å­ç›®å½•æ ¼å¼ä¸åŒ¹é…: {subfolder_name}")
    return None

# --- æ¸…ç†å…ƒæ•°æ® ---
def clean_metadata(metadata_dict):
    return {k: v for k, v in metadata_dict.items() if v is not None}

# --- åŠ è½½æ ‡ç­¾æ–‡ä»¶ ---
def load_labels_from_txt(label_file):
    labels = {}
    if not os.path.exists(label_file):
        print(f"ğŸŸ¡ æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {label_file}")
        return labels

    try:
        with open(label_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and '&' in line:
                    parts = line.split('&')
                    if len(parts) >= 3:
                        frame_filename = parts[0].strip()
                        video_id = parts[1].strip()  # æ³¨æ„ï¼šè¿™é‡Œå¯èƒ½ä¸å‡†ç¡®ï¼Œæˆ‘ä»¬ä»¥ clip_id ä¸ºå‡†
                        label = parts[2].strip()
                        start_second = None
                        end_second = None
                        if len(parts) >= 5:
                            try: start_second = float(parts[3].strip())
                            except: pass
                            try: end_second = float(parts[4].strip())
                            except: pass
                        labels[frame_filename] = {
                            "label": label,
                            "video_id": video_id,
                            "start_second": start_second,
                            "end_second": end_second
                        }
        print(f"âœ… æˆåŠŸåŠ è½½ {len(labels)} æ¡æ ‡ç­¾æ•°æ®")
    except Exception as e:
        print(f"âŒ è¯»å–æ ‡ç­¾æ–‡ä»¶å¤±è´¥: {e}")
    return labels

# --- ä¸»å¤„ç†é€»è¾‘ ---
labels_data = load_labels_from_txt(label_file_path)
last_frame_per_clip = {}  # æŒ‰ clip_id ä¿å­˜æœ€åä¸€å¸§

if not os.path.exists(root_frame_dir):
    print(f"âŒ å¸§ç›®å½•ä¸å­˜åœ¨: {root_frame_dir}")
else:
    subfolders = sorted([
        f for f in os.listdir(root_frame_dir)
        if os.path.isdir(os.path.join(root_frame_dir, f))
    ])

    print(f"ğŸ” å‘ç° {len(subfolders)} ä¸ªå­ç›®å½•")

    for subfolder in subfolders:
        subfolder_path = os.path.join(root_frame_dir, subfolder)
        subfolder_copied_dir = os.path.join(copied_frames_base_dir, subfolder)
        os.makedirs(subfolder_copied_dir, exist_ok=True)

        # è§£æå­ç›®å½•
        result = extract_subfolder_info(subfolder)
        if result is None:
            continue
        label, clip_id, start, end, original_video_id = result

        print(f"\nğŸ“ å¤„ç†å­ç›®å½•: {subfolder}")
        print(f"   â†’ label={label}, clip_id={clip_id}, original_video_id={original_video_id}, start={start}, end={end}")

        # è·å–å¸§æ–‡ä»¶
        frame_files = sorted([
            f for f in os.listdir(subfolder_path)
            if f.lower().endswith((".jpg", ".png", ".jpeg")) and f.startswith("frame_")
        ])
        if not frame_files:
            print(f"   âš ï¸ æ— æœ‰æ•ˆå¸§æ–‡ä»¶ï¼Œè·³è¿‡")
            continue

        print(f"   ğŸ–¼ï¸  å…± {len(frame_files)} å¸§")

        for filename in frame_files:
            path = os.path.join(subfolder_path, filename)
            try:
                # å¤åˆ¶å¸§
                copied_frame_path = os.path.join(subfolder_copied_dir, filename)
                if not os.path.exists(copied_frame_path):
                    shutil.copy2(path, copied_frame_path)

                # è§£æå¸§ç´¢å¼•
                frame_index = extract_frame_info(filename)
                if frame_index is None:
                    continue

                # è·å–æ ‡ç­¾
                label_info = labels_data.get(filename, {"label": "unknown"})
                label_from_file = label_info["label"]

                # å›¾åƒåŠ è½½ä¸ç‰¹å¾æå–
                image = Image.open(path).convert("RGB")
                inputs = processor(images=image, return_tensors="pt").to(device)
                with torch.no_grad():
                    image_feature = model.get_image_features(**inputs)
                image_feature = image_feature / image_feature.norm(p=2, dim=-1, keepdim=True)

                text_inputs = processor(text=label_from_file, return_tensors="pt", padding=True).to(device)
                with torch.no_grad():
                    text_feature = model.get_text_features(**text_inputs)
                text_feature = text_feature / text_feature.norm(p=2, dim=-1, keepdim=True)

                # èåˆç‰¹å¾
                combined_feature = (image_feature.cpu().numpy().flatten() + text_feature.cpu().numpy().flatten()) / 2.0
                all_embeddings.append(combined_feature)

                # æ„å»ºå…ƒæ•°æ®ï¼šä½¿ç”¨ clip_id ä½œä¸º video_id
                raw_metadata = {
                    "source_dir": subfolder,
                    "original_frame_file_path": path,
                    "frame_file_path": copied_frame_path,
                    "frame_index": frame_index,
                    "label": label_from_file,
                    "video_id": clip_id,                    # âœ… ç”¨ clip_id ä½œä¸º video_id
                    "original_video_id": original_video_id, # ğŸ”½ ä¿ç•™åŸå§‹è§†é¢‘ID
                    "start_time": start,
                    "end_time": end,
                    "parsed_label": label,
                    "clip_id": clip_id                     # âœ… å†—ä½™å­˜å‚¨ï¼Œä¾¿äºæŸ¥è¯¢
                }
                cleaned_metadata = clean_metadata(raw_metadata)

                # ç”Ÿæˆå”¯ä¸€ ID
                unique_frame_id = f"{clip_id}_{filename}"
                all_frame_ids.append(unique_frame_id)
                all_metadatas.append(cleaned_metadata)

                # æ›´æ–°æœ€åä¸€å¸§ï¼ˆæŒ‰ clip_id åˆ†ç»„ï¼‰
                if (clip_id not in last_frame_per_clip or 
                    frame_index > last_frame_per_clip[clip_id]['frame_index']):
                    last_frame_per_clip[clip_id] = {
                        'path': path,
                        'copied_path': copied_frame_path,
                        'frame_index': frame_index,
                        'metadata': cleaned_metadata
                    }

            except Exception as e:
                print(f"âŒ å¤„ç†å¸§å¤±è´¥ {path}: {e}")

# --- å†™å…¥ ChromaDB ---
if all_embeddings:
    print(f"\nğŸ“¦ æ­£åœ¨æ‰¹é‡å†™å…¥ ChromaDB ({len(all_embeddings)} æ¡æ•°æ®)...")

    batch_size = 100
    total_count = len(all_frame_ids)
    try:
        for i in range(0, total_count, batch_size):
            end_idx = min(i + batch_size, total_count)
            chroma_collection.add(
                embeddings=all_embeddings[i:end_idx],
                metadatas=all_metadatas[i:end_idx],
                ids=all_frame_ids[i:end_idx]
            )
        print(f"âœ… æˆåŠŸå†™å…¥ {total_count} æ¡æ•°æ®åˆ° ChromaDB")
    except Exception as e:
        print(f"âŒ å†™å…¥ ChromaDB å¤±è´¥: {e}")
        raise

    # ğŸ” éªŒè¯æ•°æ®
    try:
        sample = chroma_collection.get(limit=3, include=["metadatas"])
        print("\nğŸ” éªŒè¯å‰3æ¡æ•°æ®:")
        for idx, meta in enumerate(sample['metadatas']):
            vid = meta.get("video_id", "MISSING")        # â† è¿™å°±æ˜¯ clip_id
            orig = meta.get("original_video_id", "MISSING")
            print(f"  [{idx}] video_id={vid}, original_video_id={orig}")
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
else:
    print("âŒ æ²¡æœ‰ç”Ÿæˆä»»ä½• embeddingã€‚")

# --- ä¿å­˜æ¯ä¸ªç‰‡æ®µçš„æœ€åä¸€å¸§ ---
print(f"\nğŸ’¾ ä¿å­˜æ¯ä¸ªç‰‡æ®µçš„æœ€åä¸€å¸§åˆ° {last_frames_dir}...")
for clip_id, info in last_frame_per_clip.items():
    src_path = info['path']
    dst_path = os.path.join(last_frames_dir, f"{clip_id}_last_frame.jpg")
    try:
        img = Image.open(src_path).convert("RGB")
        img.save(dst_path, "JPEG")
        print(f"  âœ… {clip_id} -> {dst_path}")
    except Exception as e:
        print(f"  âŒ ä¿å­˜å¤±è´¥ {clip_id}: {e}")

print("\nğŸ‰ âœ… æ•°æ®åº“æ„å»ºå®Œæˆï¼")